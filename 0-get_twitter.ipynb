{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch twitter text by API\n",
    "This file is used to fetch twetter via Twitter API v2,\n",
    "\n",
    "all tweets saved as a dict in tweets.npy\n",
    "\n",
    "Author: Xiaofeng Zhang\n",
    "\n",
    "Email: Xiaofzhang1@student.unimelb.edu.au\n",
    "\n",
    "SID: 1194655\n",
    "\n",
    "Reference: https://docs.tweepy.org/en/stable/client.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tweets id from\n",
    "def txt2set(filepath):\n",
    "    _set = set()\n",
    "    with open(filepath,\"r\") as f:\n",
    "        ids=f.readline()\n",
    "        while ids :\n",
    "            ids = ids.replace(\"\\n\",\"\")\n",
    "            ids = ids.split(\",\")\n",
    "            for id in ids:\n",
    "                _set.add(id)\n",
    "            ids = f.readline()\n",
    "    return _set\n",
    "test_set = txt2set(\"test.data.txt\")\n",
    "print(len(test_set))\n",
    "\n",
    "train_set =  txt2set(\"train.data.txt\")\n",
    "print(len(train_set))\n",
    "dev_set = txt2set(\"dev.data.txt\")\n",
    "print(len(dev_set))\n",
    "tweet_set = train_set.union(test_set)\n",
    "tweet_set = tweet_set.union(dev_set)\n",
    "\n",
    "covid_set = txt2set(\"covid.data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize the npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"tweets.npy\"):\n",
    "    data_dict = np.load(\"tweets.npy\",allow_pickle=True).item()\n",
    "else:\n",
    "    data_dict = {}\n",
    "    np.save(data_dict)\n",
    "\n",
    "for id in tweet_set:\n",
    "    if id not in data_dict:\n",
    "       data_dict[id] = None\n",
    "#print(type(id))\n",
    "np.save(\"tweets.npy\",data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = \"BearerToken\"\n",
    "train_data = \"train.data.txt\"\n",
    "train_label = \"train.label.txt\"\n",
    "\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = np.load(\"tweets.npy\",allow_pickle=True).item()\n",
    "\n",
    "#print(len(tweet_set))\n",
    "tweet_list = list(tweet_set)\n",
    "#print(len(tweet_list))\n",
    "splited_list = []\n",
    "\n",
    "dev_list = list(dev_set)\n",
    "for i in range(0,len(dev_list),100):\n",
    "    templist = dev_list[i:i+100]\n",
    "    splited_list.append(templist)   \n",
    "for i in range(len(splited_list)):\n",
    "    ids = splited_list[i]\n",
    "    head = ids[0]\n",
    "\n",
    "    temp_t = [data_dict[id] for id in ids]\n",
    "    if (any(t is None for t in temp_t) ):\n",
    "       print(temp_t)\n",
    "\n",
    "    try:\n",
    "        print(i)\n",
    "        Flag = False\n",
    "        if (any(t is None for t in temp_t) ):\n",
    "            Flag = True\n",
    "\n",
    "        if Flag:\n",
    "            tweets = client.get_tweets(ids=ids, tweet_fields=['context_annotations','created_at','geo'])\n",
    "       \n",
    "            for tweet in tweets.data:\n",
    "                #print(tweet.id)\n",
    "                data_dict[str(tweet.id)] = {'text':tweet.text,'created_at':tweet.created_at}\n",
    "                #print(tweet.text)\n",
    "                #print(tweet.created_at)\n",
    "                #print('*'*10)\n",
    "            #print(tweets.errors)\n",
    "            for tweet in tweets.errors:\n",
    "                data_dict[str(tweet['value'])] = tweet['title']\n",
    "                #print(data_dict[str(tweet['value'])])\n",
    "            print(i,\"success\")\n",
    "        else:\n",
    "            print(i,\"passed\")\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(i,e)\n",
    "        \n",
    "        np.save(\"tweets.npy\",data_dict)\n",
    "        break\n",
    "\n",
    "\n",
    "#print(data_dict)\n",
    "\n",
    "np.save(\"tweets.npy\",data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how much tweets are fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = np.load(\"covid.npy\",allow_pickle=True).item()\n",
    "counter = 0\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "\n",
    "for t in covid_set:\n",
    "    if test_dict[t] != None:\n",
    "        if type(test_dict[t]) != type(''):\n",
    "            #print(test_dict[t])\n",
    "            counter +=1\n",
    "        else :\n",
    "            counter1 +=1\n",
    "    else:\n",
    "        counter2 +=1\n",
    "print(counter,\"successful\")\n",
    "print(counter1,\"errors\")\n",
    "print(counter2,\"has not get\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edcda8d2a73236de09051cdde745a65eb7ed2a749b88f01ef4a8b567e29cd136"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
